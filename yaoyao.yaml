model:
  base_learning_rate: 5e-5
  target: ldm.models.autoencoder.AutoencoderKL
  params:
    monitor: "val/loss"
    embed_dim: 4
    
    lossconfig:
      target: ldm.modules.losses.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 1.0e-06
        disc_weight: 0.5

    ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0  
  
    encodeconfig:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        monitor: val/rec_loss
        ckpt_path: logs/2023-10-08T10-49-29_autoencoder_kl_32x32x4/checkpoints/epoch=000010.ckpt
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult:
          - 1
          - 2
          - 4
          - 4
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: torch.nn.Identity

data:
  target: train.DataModuleFromConfig
  params:
    batch_size: 64
    num_workers: 64
    wrap: false
    train:
      target: yaoyao_data.TransferTrain
      params:
        size: 256
    validation:
      target: yaoyao_data.TransferValidation
      params:
        size: 256
        
lightning:
  callbacks:
    image_logger:
      target: train.ImageLogger
      params:
        batch_frequency: 2000
        max_images: 8
        increase_log_steps: False
  trainer:
    benchmark: True
